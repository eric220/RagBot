{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ce14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from nltk.tokenize import BlanklineTokenizer, word_tokenize\n",
    "import gradio as gr\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from py_files import config\n",
    "stop = set(stopwords.words('english') + list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53413748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_scorer(set_1, test_list):\n",
    "    set_2 = set(test_list)\n",
    "    return float(len(set_1.intersection(set_2))/len(set_1.union(set_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80eb72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/corpus.txt') as f:\n",
    "    corpus = f.read()\n",
    "blt = BlanklineTokenizer()\n",
    "documents = blt.tokenize(corpus)\n",
    "leman = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49fcf758",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_set = []\n",
    "for d in documents:\n",
    "    d = re.sub('[^0-9a-zA-Z]+', ' ', d.lower())\n",
    "    word_tokens = word_tokenize(d)\n",
    "    filtered_sentence = [w.lower() for w in word_tokens if not w.lower() in stop]\n",
    "    filtered_sentence = [leman.lemmatize(w) for w in filtered_sentence]\n",
    "    doc_set.append(set(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f7e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=config.API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005f8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gpt(t_message):\n",
    "    global messages\n",
    "    if t_message == 'new conversation':\n",
    "        messages = [messages[0]]\n",
    "    elif t_message == 'messages':\n",
    "        pass\n",
    "    else:\n",
    "        message = f\"User : {t_message}\"\n",
    "        if message:\n",
    "            messages.append(\n",
    "                {\"role\": \"user\", \"content\": message},\n",
    "            )\n",
    "            chat = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "                                                  messages=messages,\n",
    "                                                 temperature = 0.0)\n",
    "        reply = chat.choices[0].message.content\n",
    "        return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f301424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some prompts for testing\n",
    "prompts = ['''Something is wrong with the on screen timer.''', \n",
    "          '''I just spent 2 hours reading the instructions. Do i get paid for this''',\n",
    "          '''can i prompt the model to generate a file''', \n",
    "          '''do i penalize the model for not using the .head function''',\n",
    "           '''do i rate the edited response or the original''',\n",
    "           '''is “Sorry we couldn't finish the response at this time. Please try again later.” considered a canned response''',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c2adaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is “Sorry we couldn't finish the response at this time. Please try again later.” considered a canned response\n",
      "Rule 1: Responses that end with “Sorry we couldn't finish the response at this time. Please try again later.” are not considered canned responses and are not unratable. The lone exception to this is if there is nothing else in the response (meaning literally no code/output and no other text).\n",
      "Rule 2: Please do not select error messages as the better response. If you receive error messages from both models, and editing is not working, use the checkbox and submit the conversation. Do not try to move forward with an erroneous response.\n",
      "Rule 3: You can use files that others have created, but please try to create a couple of your own first.\n",
      "I am a friendly bot here to help you. The question you asked is whether the response \"Sorry we couldn't finish the response at this time. Please try again later.\" is considered a canned response. Based on the rules provided, the answer is that this response is not considered a canned response.\n"
     ]
    }
   ],
   "source": [
    "internal_idxs = []\n",
    "messages = [{'role': 'system', 'content': 'you are a helpful question answering bot. Your job is to provide \\\n",
    "friendly advice regarding questions you are asked. You will receive a question and up to 3 rules to guide you. however, \\\n",
    "the rules may not apply to the question asked. for each rule, you are to think about the question and the rule and \\\n",
    "decide if the rule applies. if the rule does not apply, ignore the rule. otherwise think about how the rule\\\n",
    "applies to answer the prompt. i want your response to include the following information: \\\n",
    "tell the user you are a friendly bot, \\\n",
    "paraphrase the question \\\n",
    "provide the answer based on the rules, but do not quote the rules, \\\n",
    "your answer must be based on one of the rules\"'\n",
    "            }]\n",
    "\n",
    "#This is virtually a copy of the method used to get the doc set,Abstract Abstract, Abstract\n",
    "def get_test_set(text):\n",
    "    d = re.sub('[^0-9a-zA-Z]+', ' ', text.lower())\n",
    "    word_tokens = word_tokenize(d)\n",
    "    filtered_sentence = [w.lower() for w in word_tokens if not w.lower() in stop]\n",
    "    filtered_sentence = [leman.lemmatize(w) for w in filtered_sentence]\n",
    "    return set(filtered_sentence)\n",
    "\n",
    "\n",
    "def get_rules_idxs(t_docs_set, test_set):\n",
    "    j_scores = []\n",
    "    for t_d in t_docs_set:\n",
    "        j_scores.append(jaccard_scorer(t_d, test_set))\n",
    "    idxs = np.argpartition(np.array(j_scores), -3)[-3:]\n",
    "    idxs = [i for i in idxs if j_scores[i] != 0]\n",
    "    return idxs\n",
    "\n",
    "def append_rules(idxs, t_prompts):\n",
    "    for i, rule_idx in enumerate(idxs):\n",
    "        t_prompts += f'\\nRule {i+1}: {documents[rule_idx]}'\n",
    "    return t_prompts\n",
    "\n",
    "def main(text):\n",
    "    test_set = get_test_set(text)\n",
    "    idxs = get_rules_idxs(doc_set, test_set)\n",
    "    idxs = list(reversed(idxs))\n",
    "    internal_idxs.append(idxs)\n",
    "    prompt_w_rules = append_rules(idxs, text)\n",
    "    print(prompt_w_rules)\n",
    "    return chat_with_gpt(f'answer the following question, use the rules given as a guideline: {prompt_w_rules}')\n",
    "\n",
    "prompt = prompts[5]\n",
    "print(main(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095fbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py_3.9]",
   "language": "python",
   "name": "conda-env-py_3.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
