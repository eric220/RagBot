{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b951372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from py_files import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d4740af",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=config.API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564e7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [text], dimensions = 256, model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0113d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/corpus.txt') as f:\n",
    "    corpus = f.read()\n",
    "blt = BlanklineTokenizer()\n",
    "documents = blt.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bbb99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(documents, columns = ['faq'])\n",
    "df['ada_embedding'] = df.faq.apply(lambda x: get_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a00cc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gpt(t_message, messages):\n",
    "    if t_message == 'new conversation':\n",
    "        messages = [messages[0]]\n",
    "    elif t_message == 'messages':\n",
    "        pass\n",
    "    else:\n",
    "        message = f\"{t_message}\"\n",
    "        if message:\n",
    "            messages.append(\n",
    "                {\"role\": \"user\", \"content\": message},\n",
    "            )\n",
    "            chat = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
    "                                                  temperature=0.0,\n",
    "                                                  messages=messages)\n",
    "        reply = chat.choices[0].message.content\n",
    "        return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37320694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rules(idxs, t_prompts):\n",
    "    if len(idxs) > 0:\n",
    "        for i, rule_idx in enumerate(idxs):\n",
    "            t_prompts += f'\\nGuidelines {i+1}: {documents[rule_idx]}'\n",
    "    else:\n",
    "        t_prompts += f'\\n:There are no guidelines'\n",
    "    return t_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7008ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "def main(text):\n",
    "    '''messages = [{'role': 'system', 'content': 'You are a friendly and helpful question answering bot. Read \\\n",
    "through the guidelines provided and craft an appropriate answer to the question based on the guidelines. If you \\\n",
    "do not think the guidelines are applicable to the question let the user know you are unsure of the answer. Be \\\n",
    "sure to include a friendly outro'\n",
    "            }]'''\n",
    "    messages = [{'role': 'system', 'content': 'you are a helpful question answering bot. Your job is to provide \\\n",
    "friendly advice regarding questions you are asked. You will receive a question and up to 3 rules to guide you. however, \\\n",
    "the rules may not apply to the question asked. for each rule, you are to think about the question and the rule and \\\n",
    "decide if the rule applies. if the rule does not apply, ignore the rule. otherwise think about how the rule\\\n",
    "applies to answer the prompt. i want your response to include the following information: \\\n",
    "tell the user you are a friendly bot, \\\n",
    "paraphrase the question \\\n",
    "provide the answer based on the rules, but do not quote the rules, \\\n",
    "your answer must be based on one of the rules\"'\n",
    "            }]\n",
    "    query_embedding = np.array(get_embedding(text)).reshape(1,-1)\n",
    "    df['similarities'] = df.ada_embedding.apply(lambda x: cosine_similarity(np.array(x).reshape(1,-1), query_embedding))\n",
    "    idxs = df[df['similarities'] > threshold].index\n",
    "    if len(idxs) > 0:\n",
    "        prompt_w_rules = append_rules(idxs, text)\n",
    "        print(prompt_w_rules)\n",
    "        return chat_with_gpt(f'Here is the question: {prompt_w_rules}?', messages)\n",
    "    else:\n",
    "        return \"I'm sorry, please rephrase the question.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac80e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some prompts for testing\n",
    "prompts = ['''Something is wrong with the on screen timer. Should i use my own timer''', \n",
    "          '''I just spent 2 hours reading the instructions. Do i get paid for this''',\n",
    "          '''can i prompt the model to generate a file''', \n",
    "          '''do i penalize the model for not using the .head function''',\n",
    "           '''do i rate the edited response or the original''',\n",
    "           '''is “Sorry we couldn't finish the response at this time. Please try again later.” considered a canned response''',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4228084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something is wrong with the on screen timer. Should i use my own timer\n",
      "Guidelines 1: Use your own, separate timer for tracking payment. The timer on the screen is more related to how Data Annotation assigns tasks to different users.\n",
      "Hello! I'm a friendly bot here to help. It sounds like you're having trouble with the on-screen timer. In this case, it would be a good idea to use your own timer to track time accurately. This way, you can ensure that you are keeping track of time for your tasks effectively.\n"
     ]
    }
   ],
   "source": [
    "print(main(prompts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e04b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py_3.9]",
   "language": "python",
   "name": "conda-env-py_3.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
